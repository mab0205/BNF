{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grafo import *\n",
    "import numpy as np\n",
    "from operator import index\n",
    "from traceback import print_tb\n",
    "# import o alfabeto em codigo Ascii \n",
    "import string \n",
    "# manipular os dados de excel com xlrd\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criacao do Alfabeto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARAIBLES GLOBALES\n",
    "tamanhoAlfabeto = len(string.printable)\n",
    "alfabeto = []\n",
    "# Ajuste do numero de estados para criar o automato\n",
    "numEstados = 41 #son 40 estados en total pero como el rango de [0;40] tiene que se x<41\n",
    "estadosList = [i for i in range(numEstados)]\n",
    "\n",
    "def criaAlfabeto():\n",
    "    alfabeto.extend(string.printable)  #cria uma nova lista contendo o alfabeto\n",
    "\n",
    "estadosFinais=[1,3,4,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura e criacao da Tabela de Simbolos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criaTabelaSimbolos(tabelaSimbolos):\n",
    "    try:\n",
    "        # import banco de dados palabras reservadas (excel.xls) \n",
    "        excel = xlrd.open_workbook('C:/Users/gaboh/Documents/GitHub/BNF/Tabela-Simbolos2.xls') #import xlrd\n",
    "        #excel = xlrd.open_workbook('/home/moskbr/Documentos/git/BNF/Tabela-Simbolos2.xls')\n",
    "        sh = excel.sheet_by_index(0) #Folha 1 ou sheet 1\n",
    "    except:\n",
    "        print(\"Exception ->Tabela de simbolos tem que ser um doc Excel do tipo .xls\")\n",
    "\n",
    "    \n",
    "    numColumnas = sh.nrows-1\n",
    "    for key in range(numColumnas):\n",
    "        cellCadeia = sh.cell(key+1,1).value\n",
    "        cellCategoria = sh.cell(key+1,2).value\n",
    "        cadeia = str(cellCadeia)\n",
    "        tabelaSimbolos[cadeia.upper()] = cellCategoria\n",
    "    # Tabela Simbolos -> colocar as pabras dentro de uma tabela hash ( Em python o dictionary representa a tabela hash )\n",
    "    #print(tabelaSimbolos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcao do Automato "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criaAutomato(grafo): \n",
    "    \n",
    "    for x in range(numEstados): agregar(grafo, estadosList[x]) # Cria o grafo de 40 estados\n",
    "    letras=[]\n",
    "    algarismos=[]\n",
    "\n",
    "    for cont in range(0,52): #armazena so as letras do alfabeto\n",
    "        letras.append(alfabeto[cont+10])\n",
    "    for cont in range(0,10): # armazena so os numeros do alfabeto \n",
    "        algarismos.append(alfabeto[cont])\n",
    "    \n",
    "    #for cont in algarismos: #armazena em cada transicao um digito\n",
    "    relacionar(grafo, estadosList[0], estadosList[1], algarismos)\n",
    "    relacionar(grafo, estadosList[1], estadosList[1], algarismos)\n",
    "    relacionar(grafo, estadosList[2], estadosList[3], algarismos)\n",
    "    relacionar(grafo, estadosList[3], estadosList[3], algarismos)\n",
    "\n",
    "    #for cont in letras: #armazena em cada transicao o conjunto de letras\n",
    "    relacionar(grafo, estadosList[0], estadosList[4], letras)\n",
    "    relacionar(grafo, estadosList[4], estadosList[4], alfabeto)\n",
    "    \n",
    "    relacionar(grafo, estadosList[1], estadosList[2], '.')\n",
    "    relacionar(grafo, estadosList[0], estadosList[5], '\\\\')\n",
    "    relacionar(grafo, estadosList[5], estadosList[6], 'n')\n",
    "    relacionar(grafo, estadosList[5], estadosList[7], '\\\\')\n",
    "    relacionar(grafo, estadosList[0], estadosList[8], '(')\n",
    "    relacionar(grafo, estadosList[0], estadosList[9], ')')\n",
    "    relacionar(grafo, estadosList[0], estadosList[10], '{')\n",
    "    relacionar(grafo, estadosList[0], estadosList[11], '}')\n",
    "    relacionar(grafo, estadosList[0], estadosList[12], '[')\n",
    "    relacionar(grafo, estadosList[0], estadosList[13], ']')\n",
    "    relacionar(grafo, estadosList[0], estadosList[14], '=')\n",
    "    relacionar(grafo, estadosList[14], estadosList[15], '=')\n",
    "    relacionar(grafo, estadosList[0], estadosList[16], '+')\n",
    "    relacionar(grafo, estadosList[16], estadosList[17], '=')\n",
    "    relacionar(grafo, estadosList[16], estadosList[18], '+')\n",
    "    relacionar(grafo, estadosList[0], estadosList[19], '-')\n",
    "    relacionar(grafo, estadosList[19], estadosList[20], '=')\n",
    "    relacionar(grafo, estadosList[19], estadosList[21], '-')\n",
    "    relacionar(grafo, estadosList[0], estadosList[22], '*')\n",
    "    relacionar(grafo, estadosList[22], estadosList[23], '=')\n",
    "    relacionar(grafo, estadosList[0], estadosList[24], '/')\n",
    "    relacionar(grafo, estadosList[24], estadosList[25], '=')\n",
    "    relacionar(grafo, estadosList[0], estadosList[26], '%')\n",
    "    relacionar(grafo, estadosList[26], estadosList[27], '=')\n",
    "    relacionar(grafo, estadosList[0], estadosList[28], '!')\n",
    "    relacionar(grafo, estadosList[28], estadosList[29], '=')\n",
    "    relacionar(grafo, estadosList[0], estadosList[30], '>')\n",
    "    relacionar(grafo, estadosList[30], estadosList[31], '=')\n",
    "    relacionar(grafo, estadosList[0], estadosList[32], '<')\n",
    "    relacionar(grafo, estadosList[32], estadosList[33], '=')\n",
    "    relacionar(grafo, estadosList[32], estadosList[29], '>')\n",
    "    relacionar(grafo, estadosList[0], estadosList[34], '&')\n",
    "    relacionar(grafo, estadosList[34], estadosList[35], '&')\n",
    "    relacionar(grafo, estadosList[0], estadosList[36], '|')\n",
    "    relacionar(grafo, estadosList[36], estadosList[37], '|')\n",
    "    relacionar(grafo, estadosList[0], estadosList[38], ';')\n",
    "    relacionar(grafo, estadosList[0], estadosList[39], '\"')\n",
    "    relacionar(grafo, estadosList[0], estadosList[40], ',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise léxica (Scanner)\n",
    "* Tratamento de Espacios \n",
    "* Eliminar comentários\n",
    "* Contar número de linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideLexemas(lexema, contColumnas, tabelaSimbolos):\n",
    "    for palavra in lexema:\n",
    "        for letra in palavra:\n",
    "            #contColumnas+=1\n",
    "            try:\n",
    "                if (palavra.index(letra) != len(palavra)):\n",
    "                    prox = palavra[palavra.index(letra)+1]\n",
    "            except:\n",
    "                prox = None\n",
    "\n",
    "            if prox in tabelaSimbolos:\n",
    "                letra = letra + prox\n",
    "                        \n",
    "            if letra in tabelaSimbolos and len(palavra) > len(letra):\n",
    "                lista = palavra.split(letra)\n",
    "                lista.append(letra)\n",
    "                      \n",
    "                for s in lista:\n",
    "                    if s != '':\n",
    "                        lexema.append(s)\n",
    "                                \n",
    "                lista.clear()\n",
    "                lexema.remove(palavra)\n",
    "                break\n",
    "    \n",
    "    for palavra in lexema: # ajusta o ponto e virgula para o final da lista\n",
    "        if palavra == \";\":\n",
    "            lexema.append(palavra)\n",
    "            lexema.remove(palavra)\n",
    "            break\n",
    "\n",
    "    #print(lexema)\n",
    "    return lexema    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuperacao de Erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Erro(tipo, X, Y, erro):\n",
    "    if tipo == \"Lexico\":\n",
    "        print(\"[Erro: Análise {}]: símbolo incorreto na linha {}, coluna {}. O símbolo {} não pertence ao alfabeto da linguagem.\".format(tipo, X, Y, erro))\n",
    "    \n",
    "    #print(\"[Erro: Análise Léxica]: símbolo incorreto na linha X, coluna Y. O variavel “@” não pertence ao alfabeto da linguagem.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CYK CODE & BNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analiseSintatica(tokens_lexema, tabelaSimbolos):\n",
    "    if (tokens_lexema[0]in tabelaSimbolos.values()):\n",
    "        if( tokens_lexema[0] == 'TK_While' and 'TK_If'):\n",
    "            #simbolos no terminais\n",
    "            no_terminales_0 = []\n",
    "            terminales_0 = []\n",
    "\n",
    "            #regras da gramatica \n",
    "            Regras_0 = {\n",
    "                \n",
    "            }\n",
    "        elif(tokens_lexema[0] == 'TK_Inteiro' and 'TK_Flutuante' and 'TK_Char'):\n",
    "            #simbolos no terminais\n",
    "            no_terminales_1 = []\n",
    "            terminales_1 = []\n",
    "\n",
    "            #regras da gramatica \n",
    "            Regras_1 = {\n",
    "                \n",
    "            }\n",
    "        elif(tokens_lexema[0] == 'TK_Write'):\n",
    "            #simbolos no terminais\n",
    "            no_terminales_2 = []\n",
    "            terminales_2 = []\n",
    "\n",
    "            #regras da gramatica \n",
    "            Regras_2 = {\n",
    "                \n",
    "            }\n",
    "        elif(tokens_lexema[0] == 'TK_Read'):\n",
    "            #simbolos no terminais\n",
    "            no_terminales_3 = []\n",
    "            terminales_3 = []\n",
    "\n",
    "            #regras da gramatica \n",
    "            Regras_3 = {\n",
    "                \n",
    "            }\n",
    "        elif(tokens_lexema[0] == 'TK_Comentario'):\n",
    "            #simbolos no terminais\n",
    "            no_terminales_4 = []\n",
    "            terminales_4 = []\n",
    "\n",
    "            #regras da gramatica \n",
    "            Regras_4 = {\n",
    "                \n",
    "            }                        \n",
    "        elif(tokens_lexema[0] == 'TK_Identificador'):\n",
    "            #simbolos no terminais\n",
    "            no_terminales_5 = []\n",
    "            terminales_5 = []\n",
    "\n",
    "            #regras da gramatica \n",
    "            Regras_5 = {\n",
    "                \n",
    "            }\n",
    "\n",
    "        elif(tokens_lexema[0] == 'TK_Fecha_Chaves'):\n",
    "            #simbolos no terminais\n",
    "            no_terminales_6 = []\n",
    "            terminales_6 = []\n",
    "\n",
    "            #regras da gramatica \n",
    "            Regras_6 = {\n",
    "                \n",
    "            }    \n",
    "        else:\n",
    "            print(\"erro semantica, primeira palavra\")      \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcao do algoritmo CYK\n",
    "# w eh a lista que ele debe fazer a leitura e identificacao \n",
    "def cykParser(w, terminais, noterminais, regra ):\n",
    "    n = len(w) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main e leitura do arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    criaAlfabeto()\n",
    "    tabelaSimbolos = {} #dictionary\n",
    "    criaTabelaSimbolos(tabelaSimbolos)\n",
    "\n",
    "    tokens_lexema = []\n",
    "\n",
    "    grafo = Grafo()\n",
    "    criaAutomato(grafo)\n",
    "    # variaveis para armazenar os tokens dependo do tipo \n",
    "    contFloat = 0 \n",
    "    contInt = 0 \n",
    "    contString = 0 \n",
    "\n",
    "    # Analise Lexica\n",
    "    contLinhas = 0\n",
    "    contColumnas = 0\n",
    "    lista = []\n",
    "    # Leitura do arquivo \n",
    "    with open('teste.teste') as arquivo:\n",
    "        for linha in arquivo:\n",
    "            if linha == '\\n': continue # desconsidera linhas vazias\n",
    "            contLinhas += 1\n",
    "            lexema = linha.split()\n",
    "            lista = divideLexemas(lexema, contColumnas, tabelaSimbolos)\n",
    "            \n",
    "            for w in lista:\n",
    "                contColumnas+=1\n",
    "                if(verificaPalavra(grafo, w, estadosFinais)):\n",
    "                    try: \n",
    "                        tokens_lexema.append(tabelaSimbolos[w.upper()]) \n",
    "                        #print(tabelaSimbolos[w.upper()])\n",
    "                    except: \n",
    "                        if(w.isdigit()):\n",
    "                            tabelaSimbolos[w] = \"TK_Inteiro_\"+str(contInt)\n",
    "                            tokens_lexema.append(\"TK_Inteiro\") \n",
    "                            contInt+=1\n",
    "                        elif(isfloat(w)): \n",
    "                            tabelaSimbolos[w] = \"TK_Flutuante_\"+str(contFloat)\n",
    "                            tokens_lexema.append(\"TK_Flutuante\") \n",
    "                            contFloat+=1\n",
    "                        else: \n",
    "                            tabelaSimbolos[w.upper()] = \"TK_Identificador_\"+str(contString)\n",
    "                            tokens_lexema.append(\"TK_Identificador\") \n",
    "                            contString+=1\n",
    "                else :\n",
    "                    print(\"Erro Automato:\") \n",
    "                    #tokens_lexema.clear()\n",
    "                    Erro(\"Lexico\", contLinhas, contColumnas, w)\n",
    "                    break\n",
    "                    \n",
    "            print(tokens_lexema[0])\n",
    "            analiseSintatica(tokens_lexema, tabelaSimbolos)\n",
    "            tokens_lexema.clear()\n",
    "            \n",
    "    #print(tabelaSimbolos)\n",
    "    print(\"Numero de linhas do Codigo: {}\".format(contLinhas))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analiseSintatica2():\n",
    "    cadeia = \"a + b \".split()\n",
    "    \n",
    "    \n",
    "    print(pilha)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TK_Inteiro\n",
      "TK_Inteiro\n",
      "Erro Automato:\n",
      "[Erro: Análise Lexico]: símbolo incorreto na linha 3, coluna 7. O símbolo 1324adsfggasdf não pertence ao alfabeto da linguagem.\n",
      "TK_Identificador\n",
      "TK_If\n",
      "erro semantica, primeira palavra\n",
      "TK_Identificador_1\n",
      "erro semantica, primeira palavra\n",
      "TK_Fecha_Chaves\n",
      "TK_Comentario\n",
      "TK_Identificador\n",
      "Numero de linhas do Codigo: 8\n",
      "['2']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    analiseSintatica2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a83478b08aff42f6845beb537692bcdaf52cb9d83fb6dadbd292d42aa887aaf0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
