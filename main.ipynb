{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grafo import *\n",
    "from analiseSintatica import *\n",
    "import numpy as np\n",
    "from operator import index\n",
    "from traceback import print_tb\n",
    "# import o alfabeto em codigo Ascii \n",
    "import string \n",
    "# manipular os dados de excel com xlrd\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criacao do Alfabeto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARAIBLES GLOBALES\n",
    "tamanhoAlfabeto = len(string.printable)\n",
    "alfabeto = []\n",
    "# Ajuste do numero de estados para criar o automato\n",
    "numEstados = 29 #son 28 estados en total pero como el rango de [0;28] tiene que se x<41\n",
    "estadosList = [i for i in range(numEstados)]\n",
    "\n",
    "def criaAlfabeto():\n",
    "    alfabeto.extend(string.printable)  #cria uma nova lista contendo o alfabeto\n",
    "\n",
    "estadosFinais=[1,3,4,6,7,8,9,10,11,12,13,14,15,16,17,18,19,21,22,23,24,25,28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura e criacao da Tabela de Simbolos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criaTabelaSimbolos(tabelaSimbolos):\n",
    "    try:\n",
    "        # import banco de dados palabras reservadas (excel.xls) \n",
    "        excel = xlrd.open_workbook('C:/Users/gaboh/Documents/GitHub/COMPILADORES/BNF/Tabela-Simbolos_3.xls') #import xlrd\n",
    "        #excel = xlrd.open_workbook('/home/moskbr/Documentos/git/BNF/Tabela-Simbolos_3.xls')\n",
    "        sh = excel.sheet_by_index(0) #Folha 1 ou sheet 1\n",
    "    except:\n",
    "        print(\"Exception ->Tabela de simbolos tem que ser um doc Excel do tipo .xls\")\n",
    "\n",
    "    \n",
    "    numColumnas = sh.nrows-1\n",
    "    for key in range(numColumnas):\n",
    "        cellCadeia = sh.cell(key+1,1).value\n",
    "        cellCategoria = sh.cell(key+1,2).value\n",
    "        cadeia = str(cellCadeia)\n",
    "        tabelaSimbolos[cadeia.upper()] = cellCategoria\n",
    "    # Tabela Simbolos -> colocar as pabras dentro de uma tabela hash ( Em python o dictionary representa a tabela hash )\n",
    "    #print(tabelaSimbolos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcao do Automato "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criaAutomato(grafo): \n",
    "    \n",
    "    for x in range(numEstados): agregar(grafo, estadosList[x]) # Cria o grafo de 40 estados\n",
    "    letras=[]\n",
    "    algarismos=[]\n",
    "\n",
    "    for cont in range(0,52): #armazena so as letras do alfabeto\n",
    "        letras.append(alfabeto[cont+10])\n",
    "    for cont in range(0,10): # armazena so os numeros do alfabeto \n",
    "        algarismos.append(alfabeto[cont])\n",
    "    \n",
    "    relacionar(grafo, estadosList[0], estadosList[1], algarismos)\n",
    "    relacionar(grafo, estadosList[1], estadosList[1], algarismos)\n",
    "    relacionar(grafo, estadosList[2], estadosList[3], algarismos)\n",
    "    relacionar(grafo, estadosList[3], estadosList[3], algarismos)\n",
    "    relacionar(grafo, estadosList[0], estadosList[4], letras)\n",
    "    relacionar(grafo, estadosList[4], estadosList[4], alfabeto)\n",
    "    relacionar(grafo, estadosList[1], estadosList[2], '.')\n",
    "    relacionar(grafo, estadosList[0], estadosList[5], '\\\\')\n",
    "    relacionar(grafo, estadosList[5], estadosList[6], '\\\\')\n",
    "    relacionar(grafo, estadosList[0], estadosList[7], '(')\n",
    "    relacionar(grafo, estadosList[0], estadosList[8], ')')\n",
    "    relacionar(grafo, estadosList[0], estadosList[9], '{')\n",
    "    relacionar(grafo, estadosList[0], estadosList[10], '}')\n",
    "    relacionar(grafo, estadosList[0], estadosList[11], '=')\n",
    "    relacionar(grafo, estadosList[11], estadosList[12], '=')\n",
    "    relacionar(grafo, estadosList[0], estadosList[13], '+')\n",
    "    relacionar(grafo, estadosList[13], estadosList[14], '+')\n",
    "    relacionar(grafo, estadosList[0], estadosList[15], '-')\n",
    "    relacionar(grafo, estadosList[15], estadosList[16], '-')\n",
    "    relacionar(grafo, estadosList[0], estadosList[17], '*')\n",
    "    relacionar(grafo, estadosList[0], estadosList[18], '/')\n",
    "    relacionar(grafo, estadosList[0], estadosList[19], '%')\n",
    "    relacionar(grafo, estadosList[0], estadosList[20], '!')\n",
    "    relacionar(grafo, estadosList[20], estadosList[21], '=')\n",
    "    relacionar(grafo, estadosList[0], estadosList[22], '>')\n",
    "    relacionar(grafo, estadosList[22], estadosList[23], '=')\n",
    "    relacionar(grafo, estadosList[0], estadosList[24], '<')\n",
    "    relacionar(grafo, estadosList[24], estadosList[25], '=')\n",
    "    relacionar(grafo, estadosList[0], estadosList[26], '\"')\n",
    "    relacionar(grafo, estadosList[26], estadosList[27], algarismos)\n",
    "    relacionar(grafo, estadosList[26], estadosList[27], letras)\n",
    "    relacionar(grafo, estadosList[27], estadosList[28], '\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise léxica (Scanner)\n",
    "* Tratamento de Espacios \n",
    "* Eliminar comentários\n",
    "* Contar número de linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideLexemas(lexema, contColumnas, tabelaSimbolos):\n",
    "    for palavra in lexema:\n",
    "        for letra in palavra:\n",
    "            #contColumnas+=1\n",
    "\n",
    "            if letra == \"\\\"\":# encontra abre aspas\n",
    "                fecha_aspas = palavra[palavra.index(letra)+1]\n",
    "                i = 1\n",
    "                while fecha_aspas != \"\\\"\":# procura fecha aspas\n",
    "                    if i < len(palavra):\n",
    "                        fecha_aspas = palavra[palavra.index(letra)+i]\n",
    "                        i += 1\n",
    "                if i == len(palavra) and fecha_aspas == \"\\\"\": break\n",
    "\n",
    "            try:\n",
    "                if (palavra.index(letra) != len(palavra)):\n",
    "                    prox = palavra[palavra.index(letra)+1]\n",
    "            except:\n",
    "                prox = None\n",
    "\n",
    "            if prox in tabelaSimbolos:\n",
    "                letra = letra + prox\n",
    "                        \n",
    "            if letra in tabelaSimbolos and len(palavra) > len(letra):\n",
    "                lista = palavra.split(letra)\n",
    "                lista.append(letra)\n",
    "                      \n",
    "                for s in lista:\n",
    "                    if s != '':\n",
    "                        lexema.append(s)\n",
    "                                \n",
    "                lista.clear()\n",
    "                lexema.remove(palavra)\n",
    "                break\n",
    "    \n",
    "    for palavra in lexema: # ajusta o ponto e virgula para o final da lista\n",
    "        if palavra == \";\":\n",
    "            lexema.append(palavra)\n",
    "            lexema.remove(palavra)\n",
    "            break\n",
    "\n",
    "    return lexema\n",
    "\n",
    "# essa função elimina os espaços dentro de uma cadeia estre as aspas\n",
    "def entreAspas(linha, contLinhas):\n",
    "    indice_aspas = linha.index(\"\\\"\")\n",
    "    i = indice_aspas+1\n",
    "    entre_aspas = \"\\\"\"\n",
    "    while linha[i] != \"\\\"\":# separa a cadeia que esta entre as aspas\n",
    "      entre_aspas = entre_aspas + linha[i]\n",
    "      i += 1\n",
    "      if i >= len(linha):\n",
    "        print(\"Erro na linha {}: Esperado caractere Fecha Aspas\", contLinhas)\n",
    "    entre_aspas = entre_aspas + \"\\\"\"\n",
    "    entre_aspas = entre_aspas.replace(\" \", '')# elimina os espaços\n",
    "    linha = linha[0:indice_aspas: ] + entre_aspas + linha[i+1: :]# devolve para a lista original\n",
    "    return linha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuperacao de Erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Erro(tipo, X, Y, erro):\n",
    "    if tipo == \"Lexico\":\n",
    "        print(\"[Erro: Análise {}]: símbolo incorreto na linha {}, coluna {}. O símbolo {} não pertence ao alfabeto da linguagem.\".format(tipo, X, Y, erro))\n",
    "    \n",
    "    #print(\"[Erro: Análise Léxica]: símbolo incorreto na linha X, coluna Y. O variavel “@” não pertence ao alfabeto da linguagem.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CYK CODE & BNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sintatica(tokens_lexema, tabelaSimbolos):\n",
    "    #print(tokens_lexema[0])\n",
    "    #if (tokens_lexema[0] in tabelaSimbolos.values()):\n",
    "        if( tokens_lexema[0] == ('TK_While' or 'TK_If')):\n",
    "            print(\"aquiiiiiii\") \n",
    "            whileIf(tokens_lexema)\n",
    "        elif(tokens_lexema[0] == 'TK_Inteiro'):\n",
    "            i = 2\n",
    "            atribuiInt(tokens_lexema)\n",
    "        elif(tokens_lexema[0] == 'TK_Float'):\n",
    "            i = 2\n",
    "            atribuiFloat(tokens_lexema)\n",
    "        elif(tokens_lexema[0] == 'TK_String'):\n",
    "            i = 2\n",
    "            atribuiString(tokens_lexema)\n",
    "        elif(tokens_lexema[0] == 'TK_Write'):\n",
    "            i = 2\n",
    "            write(tokens_lexema)\n",
    "        elif(tokens_lexema[0] == 'TK_Read'):\n",
    "            i = 2\n",
    "            read(tokens_lexema)\n",
    "        elif(tokens_lexema[0] == 'TK_Comentario'):\n",
    "            i = 2\n",
    "            comentario(tokens_lexema)           \n",
    "        elif(tokens_lexema[0] == 'TK_Identificador'):\n",
    "            print(len(tokens_lexema))\n",
    "            if(len(tokens_lexema) == 2):\n",
    "                i = 2\n",
    "                operacaoIdentificador2(tokens_lexema)\n",
    "            elif(len(tokens_lexema) == 3):\n",
    "                i = 2\n",
    "                operacaoIdentificador3(tokens_lexema)\n",
    "            elif(len(tokens_lexema) == 5):\n",
    "                i = 2\n",
    "                operacaoIdentificador5(tokens_lexema)\n",
    "\n",
    "        elif(tokens_lexema[0] == 'TK_Fecha_Chaves'):\n",
    "            i = 2\n",
    "            fecharChaves(tokens_lexema)\n",
    "        else:\n",
    "            print(\"erro semantica, primeira palavra\")      \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcao do algoritmo CYK\n",
    "# w eh a lista que ele debe fazer a leitura e identificacao \n",
    "def cykParser(w, terminais, noterminais, regra ):\n",
    "    n = len(w) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main e leitura do arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    criaAlfabeto()\n",
    "    tabelaSimbolos = {} #dictionary\n",
    "    criaTabelaSimbolos(tabelaSimbolos)\n",
    "\n",
    "    tokens_lexema = []\n",
    "\n",
    "    grafo = Grafo()\n",
    "    criaAutomato(grafo)\n",
    "    # variaveis para armazenar os tokens dependo do tipo \n",
    "    contFloat = 0 \n",
    "    contInt = 0\n",
    "    contString = 0 \n",
    "    contEntreAspas = 0\n",
    "    \n",
    "    # Analise Lexica\n",
    "    contLinhas = 0\n",
    "    contColumnas = 0\n",
    "    lista = []\n",
    "    # Leitura do arquivo \n",
    "    with open('teste.teste') as arquivo:\n",
    "        for linha in arquivo:\n",
    "            if linha == '\\n': continue # desconsidera linhas vazias\n",
    "            contLinhas += 1\n",
    "\n",
    "            if \"\\\\\" in linha:\n",
    "                if linha.startswith(\"\\\\\"): continue\n",
    "                linha = linha[0:linha.index(\"\\\\\")]\n",
    "\n",
    "            if \"\\\"\" in linha:# a função elimina os espaços dentro da cadeia que esta estre aspas antes do\n",
    "                linha = entreAspas(linha, contLinhas)# split abaixo para que a cadeia nao fique fragmentada\n",
    "            \n",
    "            lexema = linha.split()\n",
    "            lista = divideLexemas(lexema, contColumnas, tabelaSimbolos)\n",
    "            \n",
    "            for w in lista:\n",
    "                contColumnas+=1\n",
    "                if(verificaPalavra(grafo, w, estadosFinais)):\n",
    "                    chave = w.upper()\n",
    "                    if(chave in tabelaSimbolos and tem_numero(tabelaSimbolos[chave]) == False):\n",
    "                        tokens_lexema.append(tabelaSimbolos[chave])\n",
    "                    elif chave in tabelaSimbolos and tem_numero(tabelaSimbolos[chave]):\n",
    "                        s = ''.join([i for i in tabelaSimbolos[chave] if not i.isdigit()])\n",
    "                        tokens_lexema.append(s)\n",
    "                    else: \n",
    "                        if(w.isdigit()):\n",
    "                            tabelaSimbolos[w] = \"TK_Inteiro_\"+str(contInt)\n",
    "                            tokens_lexema.append(\"TK_Inteiro_\")\n",
    "                            contInt+=1\n",
    "                        elif(isfloat(w)): \n",
    "                            tabelaSimbolos[w] = \"TK_Flutuante_\"+str(contFloat)\n",
    "                            tokens_lexema.append(\"TK_Flutuante_\") \n",
    "                            contFloat+=1\n",
    "                        elif w[0] == \"\\\"\":\n",
    "                            tabelaSimbolos[w] = \"TK_Entre_Aspas_\"+str(contEntreAspas)\n",
    "                            tokens_lexema.append(\"TK_Entre_Aspas_\")\n",
    "                            contEntreAspas += 1\n",
    "                        else:\n",
    "                            tabelaSimbolos[chave] = \"TK_Identificador_\"+str(contString)\n",
    "                            tokens_lexema.append(\"TK_Identificador_\") \n",
    "                            contString+=1\n",
    "                else :\n",
    "                    print(\"Erro Automato:\") \n",
    "                    #tokens_lexema.clear()\n",
    "                    Erro(\"Lexico\", contLinhas, contColumnas, w)\n",
    "                    break\n",
    "                \n",
    "            print(tokens_lexema)\n",
    "            Sintatica(tokens_lexema, tabelaSimbolos)\n",
    "            print(\".....................................................\")\n",
    "            tokens_lexema.clear()\n",
    "\n",
    "    #print(tabelaSimbolos)\n",
    "    print(\"Numero de linhas do Codigo: {}\".format(contLinhas))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tem_numero(s):\n",
    "    return any(char.isdigit() for char in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TK_While', 'TK_Abre_Parenteses', 'TK_Identificador_', 'TK_Menor', 'TK_Inteiro_', 'TK_Fecha_Parenteses', 'TK_Abre_Chaves']\n",
      "aquiiiiiii\n",
      "-----------------------------------------------------\n",
      "while_if True\n",
      "True condition\n",
      "LOG True\n",
      "True condition\n",
      "True condition\n",
      "Regra da lingaugem: False 5\n",
      ".....................................................\n",
      "['TK_Identificador_', 'TK_Atribui_Valor', 'TK_Identificador_', 'TK_Soma', 'TK_Inteiro_']\n",
      "erro semantica, primeira palavra\n",
      ".....................................................\n",
      "['TK_Write', 'TK_Abre_Parenteses', 'TK_Identificador_', 'TK_Fecha_Parenteses']\n",
      "Regra da lingaugem: False 2\n",
      ".....................................................\n",
      "['TK_Identificador_', 'TK_Atribui_Valor', 'TK_Inteiro_', 'TK_Inteiro_']\n",
      "erro semantica, primeira palavra\n",
      ".....................................................\n",
      "['TK_Identificador_', 'TK_Atribui_Valor', 'TK_Inteiro_']\n",
      "erro semantica, primeira palavra\n",
      ".....................................................\n",
      "['TK_Identificador_', 'TK_Atribui_Valor', 'TK_Identificador_', 'TK_Soma', 'TK_Identificador_']\n",
      "erro semantica, primeira palavra\n",
      ".....................................................\n",
      "['TK_Fecha_Chaves']\n",
      "True\n",
      "Regra da lingaugem: True 1\n",
      ".....................................................\n",
      "Numero de linhas do Codigo: 8\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1d387925892fc7fcb4725e0631a5c5e244fddf1bc8bf25e3f6261922298782b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
